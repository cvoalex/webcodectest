// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v6.33.0
// source: proto/monolithic.proto

package proto

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type CompositeBatchRequest struct {
	state        protoimpl.MessageState `protogen:"open.v1"`
	ModelId      string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`                // Model to use (e.g., "sanders", "bob")
	VisualFrames []byte                 `protobuf:"bytes,2,opt,name=visual_frames,json=visualFrames,proto3" json:"visual_frames,omitempty"` // 6*320*320 float32 per frame (batch_size frames)
	// Audio input - ONE OF the following:
	RawAudio      []byte `protobuf:"bytes,3,opt,name=raw_audio,json=rawAudio,proto3" json:"raw_audio,omitempty"`                   // Raw PCM audio bytes (640ms @ 16kHz = 10,240 samples)
	AudioFeatures []byte `protobuf:"bytes,4,opt,name=audio_features,json=audioFeatures,proto3" json:"audio_features,omitempty"`    // Pre-computed audio features (DEPRECATED)
	BatchSize     int32  `protobuf:"varint,5,opt,name=batch_size,json=batchSize,proto3" json:"batch_size,omitempty"`               // Number of frames in batch (1-25)
	StartFrameIdx int32  `protobuf:"varint,6,opt,name=start_frame_idx,json=startFrameIdx,proto3" json:"start_frame_idx,omitempty"` // Starting frame index for backgrounds
	SampleRate    int32  `protobuf:"varint,7,opt,name=sample_rate,json=sampleRate,proto3" json:"sample_rate,omitempty"`            // Audio sample rate (default: 16000)
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompositeBatchRequest) Reset() {
	*x = CompositeBatchRequest{}
	mi := &file_proto_monolithic_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompositeBatchRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompositeBatchRequest) ProtoMessage() {}

func (x *CompositeBatchRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompositeBatchRequest.ProtoReflect.Descriptor instead.
func (*CompositeBatchRequest) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{0}
}

func (x *CompositeBatchRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *CompositeBatchRequest) GetVisualFrames() []byte {
	if x != nil {
		return x.VisualFrames
	}
	return nil
}

func (x *CompositeBatchRequest) GetRawAudio() []byte {
	if x != nil {
		return x.RawAudio
	}
	return nil
}

func (x *CompositeBatchRequest) GetAudioFeatures() []byte {
	if x != nil {
		return x.AudioFeatures
	}
	return nil
}

func (x *CompositeBatchRequest) GetBatchSize() int32 {
	if x != nil {
		return x.BatchSize
	}
	return 0
}

func (x *CompositeBatchRequest) GetStartFrameIdx() int32 {
	if x != nil {
		return x.StartFrameIdx
	}
	return 0
}

func (x *CompositeBatchRequest) GetSampleRate() int32 {
	if x != nil {
		return x.SampleRate
	}
	return 0
}

type CompositeBatchResponse struct {
	state             protoimpl.MessageState `protogen:"open.v1"`
	CompositedFrames  [][]byte               `protobuf:"bytes,1,rep,name=composited_frames,json=compositedFrames,proto3" json:"composited_frames,omitempty"`        // JPEG-encoded frames
	InferenceTimeMs   float32                `protobuf:"fixed32,2,opt,name=inference_time_ms,json=inferenceTimeMs,proto3" json:"inference_time_ms,omitempty"`       // GPU inference time
	CompositeTimeMs   float32                `protobuf:"fixed32,3,opt,name=composite_time_ms,json=compositeTimeMs,proto3" json:"composite_time_ms,omitempty"`       // Compositing time
	TotalTimeMs       float32                `protobuf:"fixed32,4,opt,name=total_time_ms,json=totalTimeMs,proto3" json:"total_time_ms,omitempty"`                   // Total time
	AudioProcessingMs float32                `protobuf:"fixed32,5,opt,name=audio_processing_ms,json=audioProcessingMs,proto3" json:"audio_processing_ms,omitempty"` // Audio processing time
	ModelLoaded       bool                   `protobuf:"varint,6,opt,name=model_loaded,json=modelLoaded,proto3" json:"model_loaded,omitempty"`                      // True if model was loaded on-demand
	ModelLoadTimeMs   float32                `protobuf:"fixed32,7,opt,name=model_load_time_ms,json=modelLoadTimeMs,proto3" json:"model_load_time_ms,omitempty"`
	Success           bool                   `protobuf:"varint,8,opt,name=success,proto3" json:"success,omitempty"`
	Error             string                 `protobuf:"bytes,9,opt,name=error,proto3" json:"error,omitempty"`
	GpuId             int32                  `protobuf:"varint,10,opt,name=gpu_id,json=gpuId,proto3" json:"gpu_id,omitempty"` // Which GPU was used
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *CompositeBatchResponse) Reset() {
	*x = CompositeBatchResponse{}
	mi := &file_proto_monolithic_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompositeBatchResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompositeBatchResponse) ProtoMessage() {}

func (x *CompositeBatchResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompositeBatchResponse.ProtoReflect.Descriptor instead.
func (*CompositeBatchResponse) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{1}
}

func (x *CompositeBatchResponse) GetCompositedFrames() [][]byte {
	if x != nil {
		return x.CompositedFrames
	}
	return nil
}

func (x *CompositeBatchResponse) GetInferenceTimeMs() float32 {
	if x != nil {
		return x.InferenceTimeMs
	}
	return 0
}

func (x *CompositeBatchResponse) GetCompositeTimeMs() float32 {
	if x != nil {
		return x.CompositeTimeMs
	}
	return 0
}

func (x *CompositeBatchResponse) GetTotalTimeMs() float32 {
	if x != nil {
		return x.TotalTimeMs
	}
	return 0
}

func (x *CompositeBatchResponse) GetAudioProcessingMs() float32 {
	if x != nil {
		return x.AudioProcessingMs
	}
	return 0
}

func (x *CompositeBatchResponse) GetModelLoaded() bool {
	if x != nil {
		return x.ModelLoaded
	}
	return false
}

func (x *CompositeBatchResponse) GetModelLoadTimeMs() float32 {
	if x != nil {
		return x.ModelLoadTimeMs
	}
	return 0
}

func (x *CompositeBatchResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *CompositeBatchResponse) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

func (x *CompositeBatchResponse) GetGpuId() int32 {
	if x != nil {
		return x.GpuId
	}
	return 0
}

type ListModelsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_proto_monolithic_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{2}
}

type ListModelsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []*ModelInfo           `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsResponse) Reset() {
	*x = ListModelsResponse{}
	mi := &file_proto_monolithic_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsResponse) ProtoMessage() {}

func (x *ListModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsResponse.ProtoReflect.Descriptor instead.
func (*ListModelsResponse) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{3}
}

func (x *ListModelsResponse) GetModels() []*ModelInfo {
	if x != nil {
		return x.Models
	}
	return nil
}

type ModelInfo struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	ModelId        string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	Loaded         bool                   `protobuf:"varint,2,opt,name=loaded,proto3" json:"loaded,omitempty"`
	GpuId          int32                  `protobuf:"varint,3,opt,name=gpu_id,json=gpuId,proto3" json:"gpu_id,omitempty"`
	MemoryMb       int64                  `protobuf:"varint,4,opt,name=memory_mb,json=memoryMb,proto3" json:"memory_mb,omitempty"`
	RequestCount   int32                  `protobuf:"varint,5,opt,name=request_count,json=requestCount,proto3" json:"request_count,omitempty"`
	AvgInferenceMs float32                `protobuf:"fixed32,6,opt,name=avg_inference_ms,json=avgInferenceMs,proto3" json:"avg_inference_ms,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ModelInfo) Reset() {
	*x = ModelInfo{}
	mi := &file_proto_monolithic_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelInfo) ProtoMessage() {}

func (x *ModelInfo) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelInfo.ProtoReflect.Descriptor instead.
func (*ModelInfo) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{4}
}

func (x *ModelInfo) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *ModelInfo) GetLoaded() bool {
	if x != nil {
		return x.Loaded
	}
	return false
}

func (x *ModelInfo) GetGpuId() int32 {
	if x != nil {
		return x.GpuId
	}
	return 0
}

func (x *ModelInfo) GetMemoryMb() int64 {
	if x != nil {
		return x.MemoryMb
	}
	return 0
}

func (x *ModelInfo) GetRequestCount() int32 {
	if x != nil {
		return x.RequestCount
	}
	return 0
}

func (x *ModelInfo) GetAvgInferenceMs() float32 {
	if x != nil {
		return x.AvgInferenceMs
	}
	return 0
}

type LoadModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelId       string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	PreferredGpu  int32                  `protobuf:"varint,2,opt,name=preferred_gpu,json=preferredGpu,proto3" json:"preferred_gpu,omitempty"` // -1 for auto
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoadModelRequest) Reset() {
	*x = LoadModelRequest{}
	mi := &file_proto_monolithic_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoadModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoadModelRequest) ProtoMessage() {}

func (x *LoadModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoadModelRequest.ProtoReflect.Descriptor instead.
func (*LoadModelRequest) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{5}
}

func (x *LoadModelRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *LoadModelRequest) GetPreferredGpu() int32 {
	if x != nil {
		return x.PreferredGpu
	}
	return 0
}

type LoadModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Error         string                 `protobuf:"bytes,2,opt,name=error,proto3" json:"error,omitempty"`
	GpuId         int32                  `protobuf:"varint,3,opt,name=gpu_id,json=gpuId,proto3" json:"gpu_id,omitempty"`
	LoadTimeMs    float32                `protobuf:"fixed32,4,opt,name=load_time_ms,json=loadTimeMs,proto3" json:"load_time_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoadModelResponse) Reset() {
	*x = LoadModelResponse{}
	mi := &file_proto_monolithic_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoadModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoadModelResponse) ProtoMessage() {}

func (x *LoadModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoadModelResponse.ProtoReflect.Descriptor instead.
func (*LoadModelResponse) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{6}
}

func (x *LoadModelResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *LoadModelResponse) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

func (x *LoadModelResponse) GetGpuId() int32 {
	if x != nil {
		return x.GpuId
	}
	return 0
}

func (x *LoadModelResponse) GetLoadTimeMs() float32 {
	if x != nil {
		return x.LoadTimeMs
	}
	return 0
}

type UnloadModelRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelId       string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UnloadModelRequest) Reset() {
	*x = UnloadModelRequest{}
	mi := &file_proto_monolithic_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UnloadModelRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UnloadModelRequest) ProtoMessage() {}

func (x *UnloadModelRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UnloadModelRequest.ProtoReflect.Descriptor instead.
func (*UnloadModelRequest) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{7}
}

func (x *UnloadModelRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

type UnloadModelResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Error         string                 `protobuf:"bytes,2,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UnloadModelResponse) Reset() {
	*x = UnloadModelResponse{}
	mi := &file_proto_monolithic_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UnloadModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UnloadModelResponse) ProtoMessage() {}

func (x *UnloadModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UnloadModelResponse.ProtoReflect.Descriptor instead.
func (*UnloadModelResponse) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{8}
}

func (x *UnloadModelResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *UnloadModelResponse) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

type GetModelStatsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelStatsRequest) Reset() {
	*x = GetModelStatsRequest{}
	mi := &file_proto_monolithic_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelStatsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelStatsRequest) ProtoMessage() {}

func (x *GetModelStatsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelStatsRequest.ProtoReflect.Descriptor instead.
func (*GetModelStatsRequest) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{9}
}

type GetModelStatsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Models        []*ModelStats          `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelStatsResponse) Reset() {
	*x = GetModelStatsResponse{}
	mi := &file_proto_monolithic_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelStatsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelStatsResponse) ProtoMessage() {}

func (x *GetModelStatsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelStatsResponse.ProtoReflect.Descriptor instead.
func (*GetModelStatsResponse) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{10}
}

func (x *GetModelStatsResponse) GetModels() []*ModelStats {
	if x != nil {
		return x.Models
	}
	return nil
}

type ModelStats struct {
	state             protoimpl.MessageState `protogen:"open.v1"`
	ModelId           string                 `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	Loaded            bool                   `protobuf:"varint,2,opt,name=loaded,proto3" json:"loaded,omitempty"`
	GpuId             int32                  `protobuf:"varint,3,opt,name=gpu_id,json=gpuId,proto3" json:"gpu_id,omitempty"`
	MemoryMb          int64                  `protobuf:"varint,4,opt,name=memory_mb,json=memoryMb,proto3" json:"memory_mb,omitempty"`
	RequestCount      int32                  `protobuf:"varint,5,opt,name=request_count,json=requestCount,proto3" json:"request_count,omitempty"`
	TotalInferenceMs  int64                  `protobuf:"varint,6,opt,name=total_inference_ms,json=totalInferenceMs,proto3" json:"total_inference_ms,omitempty"`
	AvgInferenceMs    float32                `protobuf:"fixed32,7,opt,name=avg_inference_ms,json=avgInferenceMs,proto3" json:"avg_inference_ms,omitempty"`
	LastUsedTimestamp int64                  `protobuf:"varint,8,opt,name=last_used_timestamp,json=lastUsedTimestamp,proto3" json:"last_used_timestamp,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *ModelStats) Reset() {
	*x = ModelStats{}
	mi := &file_proto_monolithic_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelStats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelStats) ProtoMessage() {}

func (x *ModelStats) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelStats.ProtoReflect.Descriptor instead.
func (*ModelStats) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{11}
}

func (x *ModelStats) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *ModelStats) GetLoaded() bool {
	if x != nil {
		return x.Loaded
	}
	return false
}

func (x *ModelStats) GetGpuId() int32 {
	if x != nil {
		return x.GpuId
	}
	return 0
}

func (x *ModelStats) GetMemoryMb() int64 {
	if x != nil {
		return x.MemoryMb
	}
	return 0
}

func (x *ModelStats) GetRequestCount() int32 {
	if x != nil {
		return x.RequestCount
	}
	return 0
}

func (x *ModelStats) GetTotalInferenceMs() int64 {
	if x != nil {
		return x.TotalInferenceMs
	}
	return 0
}

func (x *ModelStats) GetAvgInferenceMs() float32 {
	if x != nil {
		return x.AvgInferenceMs
	}
	return 0
}

func (x *ModelStats) GetLastUsedTimestamp() int64 {
	if x != nil {
		return x.LastUsedTimestamp
	}
	return 0
}

type HealthRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthRequest) Reset() {
	*x = HealthRequest{}
	mi := &file_proto_monolithic_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthRequest) ProtoMessage() {}

func (x *HealthRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthRequest.ProtoReflect.Descriptor instead.
func (*HealthRequest) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{12}
}

type HealthResponse struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	Healthy         bool                   `protobuf:"varint,1,opt,name=healthy,proto3" json:"healthy,omitempty"`
	LoadedModels    int32                  `protobuf:"varint,2,opt,name=loaded_models,json=loadedModels,proto3" json:"loaded_models,omitempty"`
	MaxModels       int32                  `protobuf:"varint,3,opt,name=max_models,json=maxModels,proto3" json:"max_models,omitempty"`
	GpuIds          []int32                `protobuf:"varint,4,rep,packed,name=gpu_ids,json=gpuIds,proto3" json:"gpu_ids,omitempty"`
	GpuMemoryUsedGb []float32              `protobuf:"fixed32,5,rep,packed,name=gpu_memory_used_gb,json=gpuMemoryUsedGb,proto3" json:"gpu_memory_used_gb,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *HealthResponse) Reset() {
	*x = HealthResponse{}
	mi := &file_proto_monolithic_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthResponse) ProtoMessage() {}

func (x *HealthResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_monolithic_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthResponse.ProtoReflect.Descriptor instead.
func (*HealthResponse) Descriptor() ([]byte, []int) {
	return file_proto_monolithic_proto_rawDescGZIP(), []int{13}
}

func (x *HealthResponse) GetHealthy() bool {
	if x != nil {
		return x.Healthy
	}
	return false
}

func (x *HealthResponse) GetLoadedModels() int32 {
	if x != nil {
		return x.LoadedModels
	}
	return 0
}

func (x *HealthResponse) GetMaxModels() int32 {
	if x != nil {
		return x.MaxModels
	}
	return 0
}

func (x *HealthResponse) GetGpuIds() []int32 {
	if x != nil {
		return x.GpuIds
	}
	return nil
}

func (x *HealthResponse) GetGpuMemoryUsedGb() []float32 {
	if x != nil {
		return x.GpuMemoryUsedGb
	}
	return nil
}

var File_proto_monolithic_proto protoreflect.FileDescriptor

const file_proto_monolithic_proto_rawDesc = "" +
	"\n" +
	"\x16proto/monolithic.proto\x12\n" +
	"monolithic\"\x83\x02\n" +
	"\x15CompositeBatchRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x12#\n" +
	"\rvisual_frames\x18\x02 \x01(\fR\fvisualFrames\x12\x1b\n" +
	"\traw_audio\x18\x03 \x01(\fR\brawAudio\x12%\n" +
	"\x0eaudio_features\x18\x04 \x01(\fR\raudioFeatures\x12\x1d\n" +
	"\n" +
	"batch_size\x18\x05 \x01(\x05R\tbatchSize\x12&\n" +
	"\x0fstart_frame_idx\x18\x06 \x01(\x05R\rstartFrameIdx\x12\x1f\n" +
	"\vsample_rate\x18\a \x01(\x05R\n" +
	"sampleRate\"\x88\x03\n" +
	"\x16CompositeBatchResponse\x12+\n" +
	"\x11composited_frames\x18\x01 \x03(\fR\x10compositedFrames\x12*\n" +
	"\x11inference_time_ms\x18\x02 \x01(\x02R\x0finferenceTimeMs\x12*\n" +
	"\x11composite_time_ms\x18\x03 \x01(\x02R\x0fcompositeTimeMs\x12\"\n" +
	"\rtotal_time_ms\x18\x04 \x01(\x02R\vtotalTimeMs\x12.\n" +
	"\x13audio_processing_ms\x18\x05 \x01(\x02R\x11audioProcessingMs\x12!\n" +
	"\fmodel_loaded\x18\x06 \x01(\bR\vmodelLoaded\x12+\n" +
	"\x12model_load_time_ms\x18\a \x01(\x02R\x0fmodelLoadTimeMs\x12\x18\n" +
	"\asuccess\x18\b \x01(\bR\asuccess\x12\x14\n" +
	"\x05error\x18\t \x01(\tR\x05error\x12\x15\n" +
	"\x06gpu_id\x18\n" +
	" \x01(\x05R\x05gpuId\"\x13\n" +
	"\x11ListModelsRequest\"C\n" +
	"\x12ListModelsResponse\x12-\n" +
	"\x06models\x18\x01 \x03(\v2\x15.monolithic.ModelInfoR\x06models\"\xc1\x01\n" +
	"\tModelInfo\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x12\x16\n" +
	"\x06loaded\x18\x02 \x01(\bR\x06loaded\x12\x15\n" +
	"\x06gpu_id\x18\x03 \x01(\x05R\x05gpuId\x12\x1b\n" +
	"\tmemory_mb\x18\x04 \x01(\x03R\bmemoryMb\x12#\n" +
	"\rrequest_count\x18\x05 \x01(\x05R\frequestCount\x12(\n" +
	"\x10avg_inference_ms\x18\x06 \x01(\x02R\x0eavgInferenceMs\"R\n" +
	"\x10LoadModelRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x12#\n" +
	"\rpreferred_gpu\x18\x02 \x01(\x05R\fpreferredGpu\"|\n" +
	"\x11LoadModelResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x14\n" +
	"\x05error\x18\x02 \x01(\tR\x05error\x12\x15\n" +
	"\x06gpu_id\x18\x03 \x01(\x05R\x05gpuId\x12 \n" +
	"\fload_time_ms\x18\x04 \x01(\x02R\n" +
	"loadTimeMs\"/\n" +
	"\x12UnloadModelRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\"E\n" +
	"\x13UnloadModelResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x14\n" +
	"\x05error\x18\x02 \x01(\tR\x05error\"\x16\n" +
	"\x14GetModelStatsRequest\"G\n" +
	"\x15GetModelStatsResponse\x12.\n" +
	"\x06models\x18\x01 \x03(\v2\x16.monolithic.ModelStatsR\x06models\"\xa0\x02\n" +
	"\n" +
	"ModelStats\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x12\x16\n" +
	"\x06loaded\x18\x02 \x01(\bR\x06loaded\x12\x15\n" +
	"\x06gpu_id\x18\x03 \x01(\x05R\x05gpuId\x12\x1b\n" +
	"\tmemory_mb\x18\x04 \x01(\x03R\bmemoryMb\x12#\n" +
	"\rrequest_count\x18\x05 \x01(\x05R\frequestCount\x12,\n" +
	"\x12total_inference_ms\x18\x06 \x01(\x03R\x10totalInferenceMs\x12(\n" +
	"\x10avg_inference_ms\x18\a \x01(\x02R\x0eavgInferenceMs\x12.\n" +
	"\x13last_used_timestamp\x18\b \x01(\x03R\x11lastUsedTimestamp\"\x0f\n" +
	"\rHealthRequest\"\xb4\x01\n" +
	"\x0eHealthResponse\x12\x18\n" +
	"\ahealthy\x18\x01 \x01(\bR\ahealthy\x12#\n" +
	"\rloaded_models\x18\x02 \x01(\x05R\floadedModels\x12\x1d\n" +
	"\n" +
	"max_models\x18\x03 \x01(\x05R\tmaxModels\x12\x17\n" +
	"\agpu_ids\x18\x04 \x03(\x05R\x06gpuIds\x12+\n" +
	"\x12gpu_memory_used_gb\x18\x05 \x03(\x02R\x0fgpuMemoryUsedGb2\xef\x03\n" +
	"\x11MonolithicService\x12\\\n" +
	"\x13InferBatchComposite\x12!.monolithic.CompositeBatchRequest\x1a\".monolithic.CompositeBatchResponse\x12K\n" +
	"\n" +
	"ListModels\x12\x1d.monolithic.ListModelsRequest\x1a\x1e.monolithic.ListModelsResponse\x12H\n" +
	"\tLoadModel\x12\x1c.monolithic.LoadModelRequest\x1a\x1d.monolithic.LoadModelResponse\x12N\n" +
	"\vUnloadModel\x12\x1e.monolithic.UnloadModelRequest\x1a\x1f.monolithic.UnloadModelResponse\x12T\n" +
	"\rGetModelStats\x12 .monolithic.GetModelStatsRequest\x1a!.monolithic.GetModelStatsResponse\x12?\n" +
	"\x06Health\x12\x19.monolithic.HealthRequest\x1a\x1a.monolithic.HealthResponseB\x1cZ\x1ago-monolithic-server/protob\x06proto3"

var (
	file_proto_monolithic_proto_rawDescOnce sync.Once
	file_proto_monolithic_proto_rawDescData []byte
)

func file_proto_monolithic_proto_rawDescGZIP() []byte {
	file_proto_monolithic_proto_rawDescOnce.Do(func() {
		file_proto_monolithic_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_proto_monolithic_proto_rawDesc), len(file_proto_monolithic_proto_rawDesc)))
	})
	return file_proto_monolithic_proto_rawDescData
}

var file_proto_monolithic_proto_msgTypes = make([]protoimpl.MessageInfo, 14)
var file_proto_monolithic_proto_goTypes = []any{
	(*CompositeBatchRequest)(nil),  // 0: monolithic.CompositeBatchRequest
	(*CompositeBatchResponse)(nil), // 1: monolithic.CompositeBatchResponse
	(*ListModelsRequest)(nil),      // 2: monolithic.ListModelsRequest
	(*ListModelsResponse)(nil),     // 3: monolithic.ListModelsResponse
	(*ModelInfo)(nil),              // 4: monolithic.ModelInfo
	(*LoadModelRequest)(nil),       // 5: monolithic.LoadModelRequest
	(*LoadModelResponse)(nil),      // 6: monolithic.LoadModelResponse
	(*UnloadModelRequest)(nil),     // 7: monolithic.UnloadModelRequest
	(*UnloadModelResponse)(nil),    // 8: monolithic.UnloadModelResponse
	(*GetModelStatsRequest)(nil),   // 9: monolithic.GetModelStatsRequest
	(*GetModelStatsResponse)(nil),  // 10: monolithic.GetModelStatsResponse
	(*ModelStats)(nil),             // 11: monolithic.ModelStats
	(*HealthRequest)(nil),          // 12: monolithic.HealthRequest
	(*HealthResponse)(nil),         // 13: monolithic.HealthResponse
}
var file_proto_monolithic_proto_depIdxs = []int32{
	4,  // 0: monolithic.ListModelsResponse.models:type_name -> monolithic.ModelInfo
	11, // 1: monolithic.GetModelStatsResponse.models:type_name -> monolithic.ModelStats
	0,  // 2: monolithic.MonolithicService.InferBatchComposite:input_type -> monolithic.CompositeBatchRequest
	2,  // 3: monolithic.MonolithicService.ListModels:input_type -> monolithic.ListModelsRequest
	5,  // 4: monolithic.MonolithicService.LoadModel:input_type -> monolithic.LoadModelRequest
	7,  // 5: monolithic.MonolithicService.UnloadModel:input_type -> monolithic.UnloadModelRequest
	9,  // 6: monolithic.MonolithicService.GetModelStats:input_type -> monolithic.GetModelStatsRequest
	12, // 7: monolithic.MonolithicService.Health:input_type -> monolithic.HealthRequest
	1,  // 8: monolithic.MonolithicService.InferBatchComposite:output_type -> monolithic.CompositeBatchResponse
	3,  // 9: monolithic.MonolithicService.ListModels:output_type -> monolithic.ListModelsResponse
	6,  // 10: monolithic.MonolithicService.LoadModel:output_type -> monolithic.LoadModelResponse
	8,  // 11: monolithic.MonolithicService.UnloadModel:output_type -> monolithic.UnloadModelResponse
	10, // 12: monolithic.MonolithicService.GetModelStats:output_type -> monolithic.GetModelStatsResponse
	13, // 13: monolithic.MonolithicService.Health:output_type -> monolithic.HealthResponse
	8,  // [8:14] is the sub-list for method output_type
	2,  // [2:8] is the sub-list for method input_type
	2,  // [2:2] is the sub-list for extension type_name
	2,  // [2:2] is the sub-list for extension extendee
	0,  // [0:2] is the sub-list for field type_name
}

func init() { file_proto_monolithic_proto_init() }
func file_proto_monolithic_proto_init() {
	if File_proto_monolithic_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_proto_monolithic_proto_rawDesc), len(file_proto_monolithic_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   14,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_proto_monolithic_proto_goTypes,
		DependencyIndexes: file_proto_monolithic_proto_depIdxs,
		MessageInfos:      file_proto_monolithic_proto_msgTypes,
	}.Build()
	File_proto_monolithic_proto = out.File
	file_proto_monolithic_proto_goTypes = nil
	file_proto_monolithic_proto_depIdxs = nil
}
