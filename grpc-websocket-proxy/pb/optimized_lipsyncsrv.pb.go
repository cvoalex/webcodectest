// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v4.25.1
// source: optimized_lipsyncsrv.proto

package pb

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Request for optimized inference (no audio needed - pre-extracted)
type OptimizedInferenceRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelName     string                 `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	FrameId       int32                  `protobuf:"varint,2,opt,name=frame_id,json=frameId,proto3" json:"frame_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *OptimizedInferenceRequest) Reset() {
	*x = OptimizedInferenceRequest{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *OptimizedInferenceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OptimizedInferenceRequest) ProtoMessage() {}

func (x *OptimizedInferenceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OptimizedInferenceRequest.ProtoReflect.Descriptor instead.
func (*OptimizedInferenceRequest) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{0}
}

func (x *OptimizedInferenceRequest) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *OptimizedInferenceRequest) GetFrameId() int32 {
	if x != nil {
		return x.FrameId
	}
	return 0
}

// Response with optimized inference result
type OptimizedInferenceResponse struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	Success          bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	FrameId          int32                  `protobuf:"varint,2,opt,name=frame_id,json=frameId,proto3" json:"frame_id,omitempty"`
	PredictionData   []byte                 `protobuf:"bytes,3,opt,name=prediction_data,json=predictionData,proto3" json:"prediction_data,omitempty"`    // JPEG-encoded image
	PredictionShape  string                 `protobuf:"bytes,4,opt,name=prediction_shape,json=predictionShape,proto3" json:"prediction_shape,omitempty"` // e.g., "(720, 1280, 3)"
	Bounds           []int32                `protobuf:"varint,5,rep,packed,name=bounds,proto3" json:"bounds,omitempty"`                                  // [x, y, width, height]
	ProcessingTimeMs float32                `protobuf:"fixed32,6,opt,name=processing_time_ms,json=processingTimeMs,proto3" json:"processing_time_ms,omitempty"`
	// Detailed performance metrics
	PrepareTimeMs   float32 `protobuf:"fixed32,7,opt,name=prepare_time_ms,json=prepareTimeMs,proto3" json:"prepare_time_ms,omitempty"`
	InferenceTimeMs float32 `protobuf:"fixed32,8,opt,name=inference_time_ms,json=inferenceTimeMs,proto3" json:"inference_time_ms,omitempty"`
	CompositeTimeMs float32 `protobuf:"fixed32,9,opt,name=composite_time_ms,json=compositeTimeMs,proto3" json:"composite_time_ms,omitempty"`
	Error           string  `protobuf:"bytes,10,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *OptimizedInferenceResponse) Reset() {
	*x = OptimizedInferenceResponse{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *OptimizedInferenceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OptimizedInferenceResponse) ProtoMessage() {}

func (x *OptimizedInferenceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OptimizedInferenceResponse.ProtoReflect.Descriptor instead.
func (*OptimizedInferenceResponse) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{1}
}

func (x *OptimizedInferenceResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *OptimizedInferenceResponse) GetFrameId() int32 {
	if x != nil {
		return x.FrameId
	}
	return 0
}

func (x *OptimizedInferenceResponse) GetPredictionData() []byte {
	if x != nil {
		return x.PredictionData
	}
	return nil
}

func (x *OptimizedInferenceResponse) GetPredictionShape() string {
	if x != nil {
		return x.PredictionShape
	}
	return ""
}

func (x *OptimizedInferenceResponse) GetBounds() []int32 {
	if x != nil {
		return x.Bounds
	}
	return nil
}

func (x *OptimizedInferenceResponse) GetProcessingTimeMs() float32 {
	if x != nil {
		return x.ProcessingTimeMs
	}
	return 0
}

func (x *OptimizedInferenceResponse) GetPrepareTimeMs() float32 {
	if x != nil {
		return x.PrepareTimeMs
	}
	return 0
}

func (x *OptimizedInferenceResponse) GetInferenceTimeMs() float32 {
	if x != nil {
		return x.InferenceTimeMs
	}
	return 0
}

func (x *OptimizedInferenceResponse) GetCompositeTimeMs() float32 {
	if x != nil {
		return x.CompositeTimeMs
	}
	return 0
}

func (x *OptimizedInferenceResponse) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

// Batch inference request
type BatchInferenceRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelName     string                 `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	FrameIds      []int32                `protobuf:"varint,2,rep,packed,name=frame_ids,json=frameIds,proto3" json:"frame_ids,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BatchInferenceRequest) Reset() {
	*x = BatchInferenceRequest{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchInferenceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchInferenceRequest) ProtoMessage() {}

func (x *BatchInferenceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchInferenceRequest.ProtoReflect.Descriptor instead.
func (*BatchInferenceRequest) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{2}
}

func (x *BatchInferenceRequest) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *BatchInferenceRequest) GetFrameIds() []int32 {
	if x != nil {
		return x.FrameIds
	}
	return nil
}

// Batch inference response
type BatchInferenceResponse struct {
	state                 protoimpl.MessageState        `protogen:"open.v1"`
	Responses             []*OptimizedInferenceResponse `protobuf:"bytes,1,rep,name=responses,proto3" json:"responses,omitempty"`
	TotalProcessingTimeMs float32                       `protobuf:"fixed32,2,opt,name=total_processing_time_ms,json=totalProcessingTimeMs,proto3" json:"total_processing_time_ms,omitempty"`
	AvgFrameTimeMs        float32                       `protobuf:"fixed32,3,opt,name=avg_frame_time_ms,json=avgFrameTimeMs,proto3" json:"avg_frame_time_ms,omitempty"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *BatchInferenceResponse) Reset() {
	*x = BatchInferenceResponse{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchInferenceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchInferenceResponse) ProtoMessage() {}

func (x *BatchInferenceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchInferenceResponse.ProtoReflect.Descriptor instead.
func (*BatchInferenceResponse) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{3}
}

func (x *BatchInferenceResponse) GetResponses() []*OptimizedInferenceResponse {
	if x != nil {
		return x.Responses
	}
	return nil
}

func (x *BatchInferenceResponse) GetTotalProcessingTimeMs() float32 {
	if x != nil {
		return x.TotalProcessingTimeMs
	}
	return 0
}

func (x *BatchInferenceResponse) GetAvgFrameTimeMs() float32 {
	if x != nil {
		return x.AvgFrameTimeMs
	}
	return 0
}

// Load model package request
type LoadPackageRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelName     string                 `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	PackagePath   string                 `protobuf:"bytes,2,opt,name=package_path,json=packagePath,proto3" json:"package_path,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoadPackageRequest) Reset() {
	*x = LoadPackageRequest{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoadPackageRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoadPackageRequest) ProtoMessage() {}

func (x *LoadPackageRequest) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoadPackageRequest.ProtoReflect.Descriptor instead.
func (*LoadPackageRequest) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{4}
}

func (x *LoadPackageRequest) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *LoadPackageRequest) GetPackagePath() string {
	if x != nil {
		return x.PackagePath
	}
	return ""
}

// Load model package response
type LoadPackageResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	ModelName     string                 `protobuf:"bytes,2,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	FrameCount    int32                  `protobuf:"varint,3,opt,name=frame_count,json=frameCount,proto3" json:"frame_count,omitempty"`
	Error         string                 `protobuf:"bytes,4,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LoadPackageResponse) Reset() {
	*x = LoadPackageResponse{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LoadPackageResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LoadPackageResponse) ProtoMessage() {}

func (x *LoadPackageResponse) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LoadPackageResponse.ProtoReflect.Descriptor instead.
func (*LoadPackageResponse) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{5}
}

func (x *LoadPackageResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *LoadPackageResponse) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *LoadPackageResponse) GetFrameCount() int32 {
	if x != nil {
		return x.FrameCount
	}
	return 0
}

func (x *LoadPackageResponse) GetError() string {
	if x != nil {
		return x.Error
	}
	return ""
}

// Statistics request
type StatsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ModelName     string                 `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StatsRequest) Reset() {
	*x = StatsRequest{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StatsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StatsRequest) ProtoMessage() {}

func (x *StatsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StatsRequest.ProtoReflect.Descriptor instead.
func (*StatsRequest) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{6}
}

func (x *StatsRequest) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

// Statistics response
type StatsResponse struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	TotalRequests       int32                  `protobuf:"varint,1,opt,name=total_requests,json=totalRequests,proto3" json:"total_requests,omitempty"`
	AvgInferenceTimeMs  float32                `protobuf:"fixed32,2,opt,name=avg_inference_time_ms,json=avgInferenceTimeMs,proto3" json:"avg_inference_time_ms,omitempty"`
	MinInferenceTimeMs  float32                `protobuf:"fixed32,3,opt,name=min_inference_time_ms,json=minInferenceTimeMs,proto3" json:"min_inference_time_ms,omitempty"`
	MaxInferenceTimeMs  float32                `protobuf:"fixed32,4,opt,name=max_inference_time_ms,json=maxInferenceTimeMs,proto3" json:"max_inference_time_ms,omitempty"`
	FrameCount          int32                  `protobuf:"varint,5,opt,name=frame_count,json=frameCount,proto3" json:"frame_count,omitempty"`
	Device              string                 `protobuf:"bytes,6,opt,name=device,proto3" json:"device,omitempty"`
	OptimizationsActive []string               `protobuf:"bytes,7,rep,name=optimizations_active,json=optimizationsActive,proto3" json:"optimizations_active,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *StatsResponse) Reset() {
	*x = StatsResponse{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StatsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StatsResponse) ProtoMessage() {}

func (x *StatsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StatsResponse.ProtoReflect.Descriptor instead.
func (*StatsResponse) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{7}
}

func (x *StatsResponse) GetTotalRequests() int32 {
	if x != nil {
		return x.TotalRequests
	}
	return 0
}

func (x *StatsResponse) GetAvgInferenceTimeMs() float32 {
	if x != nil {
		return x.AvgInferenceTimeMs
	}
	return 0
}

func (x *StatsResponse) GetMinInferenceTimeMs() float32 {
	if x != nil {
		return x.MinInferenceTimeMs
	}
	return 0
}

func (x *StatsResponse) GetMaxInferenceTimeMs() float32 {
	if x != nil {
		return x.MaxInferenceTimeMs
	}
	return 0
}

func (x *StatsResponse) GetFrameCount() int32 {
	if x != nil {
		return x.FrameCount
	}
	return 0
}

func (x *StatsResponse) GetDevice() string {
	if x != nil {
		return x.Device
	}
	return ""
}

func (x *StatsResponse) GetOptimizationsActive() []string {
	if x != nil {
		return x.OptimizationsActive
	}
	return nil
}

// List models request
type ListModelsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{8}
}

// List models response
type ListModelsResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	LoadedModels  []string               `protobuf:"bytes,1,rep,name=loaded_models,json=loadedModels,proto3" json:"loaded_models,omitempty"`
	Count         int32                  `protobuf:"varint,2,opt,name=count,proto3" json:"count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsResponse) Reset() {
	*x = ListModelsResponse{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsResponse) ProtoMessage() {}

func (x *ListModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsResponse.ProtoReflect.Descriptor instead.
func (*ListModelsResponse) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{9}
}

func (x *ListModelsResponse) GetLoadedModels() []string {
	if x != nil {
		return x.LoadedModels
	}
	return nil
}

func (x *ListModelsResponse) GetCount() int32 {
	if x != nil {
		return x.Count
	}
	return 0
}

// Health check request
type HealthRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthRequest) Reset() {
	*x = HealthRequest{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthRequest) ProtoMessage() {}

func (x *HealthRequest) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthRequest.ProtoReflect.Descriptor instead.
func (*HealthRequest) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{10}
}

// Health check response
type HealthResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Status        string                 `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	Healthy       bool                   `protobuf:"varint,2,opt,name=healthy,proto3" json:"healthy,omitempty"`
	LoadedModels  int32                  `protobuf:"varint,3,opt,name=loaded_models,json=loadedModels,proto3" json:"loaded_models,omitempty"`
	UptimeSeconds float32                `protobuf:"fixed32,4,opt,name=uptime_seconds,json=uptimeSeconds,proto3" json:"uptime_seconds,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthResponse) Reset() {
	*x = HealthResponse{}
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthResponse) ProtoMessage() {}

func (x *HealthResponse) ProtoReflect() protoreflect.Message {
	mi := &file_optimized_lipsyncsrv_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthResponse.ProtoReflect.Descriptor instead.
func (*HealthResponse) Descriptor() ([]byte, []int) {
	return file_optimized_lipsyncsrv_proto_rawDescGZIP(), []int{11}
}

func (x *HealthResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *HealthResponse) GetHealthy() bool {
	if x != nil {
		return x.Healthy
	}
	return false
}

func (x *HealthResponse) GetLoadedModels() int32 {
	if x != nil {
		return x.LoadedModels
	}
	return 0
}

func (x *HealthResponse) GetUptimeSeconds() float32 {
	if x != nil {
		return x.UptimeSeconds
	}
	return 0
}

var File_optimized_lipsyncsrv_proto protoreflect.FileDescriptor

const file_optimized_lipsyncsrv_proto_rawDesc = "" +
	"\n" +
	"\x1aoptimized_lipsyncsrv.proto\"U\n" +
	"\x19OptimizedInferenceRequest\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\x12\x19\n" +
	"\bframe_id\x18\x02 \x01(\x05R\aframeId\"\x81\x03\n" +
	"\x1aOptimizedInferenceResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x19\n" +
	"\bframe_id\x18\x02 \x01(\x05R\aframeId\x12'\n" +
	"\x0fprediction_data\x18\x03 \x01(\fR\x0epredictionData\x12)\n" +
	"\x10prediction_shape\x18\x04 \x01(\tR\x0fpredictionShape\x12\x16\n" +
	"\x06bounds\x18\x05 \x03(\x05R\x06bounds\x12,\n" +
	"\x12processing_time_ms\x18\x06 \x01(\x02R\x10processingTimeMs\x12&\n" +
	"\x0fprepare_time_ms\x18\a \x01(\x02R\rprepareTimeMs\x12*\n" +
	"\x11inference_time_ms\x18\b \x01(\x02R\x0finferenceTimeMs\x12*\n" +
	"\x11composite_time_ms\x18\t \x01(\x02R\x0fcompositeTimeMs\x12\x14\n" +
	"\x05error\x18\n" +
	" \x01(\tR\x05error\"S\n" +
	"\x15BatchInferenceRequest\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\x12\x1b\n" +
	"\tframe_ids\x18\x02 \x03(\x05R\bframeIds\"\xb7\x01\n" +
	"\x16BatchInferenceResponse\x129\n" +
	"\tresponses\x18\x01 \x03(\v2\x1b.OptimizedInferenceResponseR\tresponses\x127\n" +
	"\x18total_processing_time_ms\x18\x02 \x01(\x02R\x15totalProcessingTimeMs\x12)\n" +
	"\x11avg_frame_time_ms\x18\x03 \x01(\x02R\x0eavgFrameTimeMs\"V\n" +
	"\x12LoadPackageRequest\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\x12!\n" +
	"\fpackage_path\x18\x02 \x01(\tR\vpackagePath\"\x85\x01\n" +
	"\x13LoadPackageResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x1d\n" +
	"\n" +
	"model_name\x18\x02 \x01(\tR\tmodelName\x12\x1f\n" +
	"\vframe_count\x18\x03 \x01(\x05R\n" +
	"frameCount\x12\x14\n" +
	"\x05error\x18\x04 \x01(\tR\x05error\"-\n" +
	"\fStatsRequest\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\"\xbb\x02\n" +
	"\rStatsResponse\x12%\n" +
	"\x0etotal_requests\x18\x01 \x01(\x05R\rtotalRequests\x121\n" +
	"\x15avg_inference_time_ms\x18\x02 \x01(\x02R\x12avgInferenceTimeMs\x121\n" +
	"\x15min_inference_time_ms\x18\x03 \x01(\x02R\x12minInferenceTimeMs\x121\n" +
	"\x15max_inference_time_ms\x18\x04 \x01(\x02R\x12maxInferenceTimeMs\x12\x1f\n" +
	"\vframe_count\x18\x05 \x01(\x05R\n" +
	"frameCount\x12\x16\n" +
	"\x06device\x18\x06 \x01(\tR\x06device\x121\n" +
	"\x14optimizations_active\x18\a \x03(\tR\x13optimizationsActive\"\x13\n" +
	"\x11ListModelsRequest\"O\n" +
	"\x12ListModelsResponse\x12#\n" +
	"\rloaded_models\x18\x01 \x03(\tR\floadedModels\x12\x14\n" +
	"\x05count\x18\x02 \x01(\x05R\x05count\"\x0f\n" +
	"\rHealthRequest\"\x8e\x01\n" +
	"\x0eHealthResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12\x18\n" +
	"\ahealthy\x18\x02 \x01(\bR\ahealthy\x12#\n" +
	"\rloaded_models\x18\x03 \x01(\x05R\floadedModels\x12%\n" +
	"\x0euptime_seconds\x18\x04 \x01(\x02R\ruptimeSeconds2\xce\x03\n" +
	"\x17OptimizedLipSyncService\x12L\n" +
	"\x11GenerateInference\x12\x1a.OptimizedInferenceRequest\x1a\x1b.OptimizedInferenceResponse\x12I\n" +
	"\x16GenerateBatchInference\x12\x16.BatchInferenceRequest\x1a\x17.BatchInferenceResponse\x12N\n" +
	"\x0fStreamInference\x12\x1a.OptimizedInferenceRequest\x1a\x1b.OptimizedInferenceResponse(\x010\x01\x128\n" +
	"\vLoadPackage\x12\x13.LoadPackageRequest\x1a\x14.LoadPackageResponse\x12)\n" +
	"\bGetStats\x12\r.StatsRequest\x1a\x0e.StatsResponse\x125\n" +
	"\n" +
	"ListModels\x12\x12.ListModelsRequest\x1a\x13.ListModelsResponse\x12.\n" +
	"\vHealthCheck\x12\x0e.HealthRequest\x1a\x0f.HealthResponseB%Z#github.com/cvoalex/lipsync-proxy/pbb\x06proto3"

var (
	file_optimized_lipsyncsrv_proto_rawDescOnce sync.Once
	file_optimized_lipsyncsrv_proto_rawDescData []byte
)

func file_optimized_lipsyncsrv_proto_rawDescGZIP() []byte {
	file_optimized_lipsyncsrv_proto_rawDescOnce.Do(func() {
		file_optimized_lipsyncsrv_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_optimized_lipsyncsrv_proto_rawDesc), len(file_optimized_lipsyncsrv_proto_rawDesc)))
	})
	return file_optimized_lipsyncsrv_proto_rawDescData
}

var file_optimized_lipsyncsrv_proto_msgTypes = make([]protoimpl.MessageInfo, 12)
var file_optimized_lipsyncsrv_proto_goTypes = []any{
	(*OptimizedInferenceRequest)(nil),  // 0: OptimizedInferenceRequest
	(*OptimizedInferenceResponse)(nil), // 1: OptimizedInferenceResponse
	(*BatchInferenceRequest)(nil),      // 2: BatchInferenceRequest
	(*BatchInferenceResponse)(nil),     // 3: BatchInferenceResponse
	(*LoadPackageRequest)(nil),         // 4: LoadPackageRequest
	(*LoadPackageResponse)(nil),        // 5: LoadPackageResponse
	(*StatsRequest)(nil),               // 6: StatsRequest
	(*StatsResponse)(nil),              // 7: StatsResponse
	(*ListModelsRequest)(nil),          // 8: ListModelsRequest
	(*ListModelsResponse)(nil),         // 9: ListModelsResponse
	(*HealthRequest)(nil),              // 10: HealthRequest
	(*HealthResponse)(nil),             // 11: HealthResponse
}
var file_optimized_lipsyncsrv_proto_depIdxs = []int32{
	1,  // 0: BatchInferenceResponse.responses:type_name -> OptimizedInferenceResponse
	0,  // 1: OptimizedLipSyncService.GenerateInference:input_type -> OptimizedInferenceRequest
	2,  // 2: OptimizedLipSyncService.GenerateBatchInference:input_type -> BatchInferenceRequest
	0,  // 3: OptimizedLipSyncService.StreamInference:input_type -> OptimizedInferenceRequest
	4,  // 4: OptimizedLipSyncService.LoadPackage:input_type -> LoadPackageRequest
	6,  // 5: OptimizedLipSyncService.GetStats:input_type -> StatsRequest
	8,  // 6: OptimizedLipSyncService.ListModels:input_type -> ListModelsRequest
	10, // 7: OptimizedLipSyncService.HealthCheck:input_type -> HealthRequest
	1,  // 8: OptimizedLipSyncService.GenerateInference:output_type -> OptimizedInferenceResponse
	3,  // 9: OptimizedLipSyncService.GenerateBatchInference:output_type -> BatchInferenceResponse
	1,  // 10: OptimizedLipSyncService.StreamInference:output_type -> OptimizedInferenceResponse
	5,  // 11: OptimizedLipSyncService.LoadPackage:output_type -> LoadPackageResponse
	7,  // 12: OptimizedLipSyncService.GetStats:output_type -> StatsResponse
	9,  // 13: OptimizedLipSyncService.ListModels:output_type -> ListModelsResponse
	11, // 14: OptimizedLipSyncService.HealthCheck:output_type -> HealthResponse
	8,  // [8:15] is the sub-list for method output_type
	1,  // [1:8] is the sub-list for method input_type
	1,  // [1:1] is the sub-list for extension type_name
	1,  // [1:1] is the sub-list for extension extendee
	0,  // [0:1] is the sub-list for field type_name
}

func init() { file_optimized_lipsyncsrv_proto_init() }
func file_optimized_lipsyncsrv_proto_init() {
	if File_optimized_lipsyncsrv_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_optimized_lipsyncsrv_proto_rawDesc), len(file_optimized_lipsyncsrv_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   12,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_optimized_lipsyncsrv_proto_goTypes,
		DependencyIndexes: file_optimized_lipsyncsrv_proto_depIdxs,
		MessageInfos:      file_optimized_lipsyncsrv_proto_msgTypes,
	}.Build()
	File_optimized_lipsyncsrv_proto = out.File
	file_optimized_lipsyncsrv_proto_goTypes = nil
	file_optimized_lipsyncsrv_proto_depIdxs = nil
}
