# Testing the Complete gRPC Video API System

## ğŸ¯ What We Built

A complete real-time lip-sync system where **ALL data flows through gRPC/WebSocket**:
- âœ… Model listing
- âœ… Model metadata  
- âœ… Video frame delivery
- âœ… Real-time lip-sync inference

**NO HTTP static file server needed!** ğŸš€

## ğŸ—ï¸ Architecture

```
Browser (WebSocket)
    â†“
Go Proxy (Load Balancer)
    â†“
gRPC Server (Python)
    â†“
PyTorch Model + Pre-loaded Videos
```

## ğŸ“‹ Prerequisites

1. **Python Environment**: `.venv312` with PyTorch, gRPC, OpenCV
2. **Go Proxy**: `lipsync-proxy.exe` compiled
3. **Model Package**: `sanders` in `minimal_server/models/sanders/`
4. **Browser**: Chrome/Edge (supports WebCodecs)

## ğŸš€ Step-by-Step Testing

### Step 1: Start gRPC Server

```powershell
cd D:\Projects\webcodecstest\minimal_server
.\start_grpc_single.bat
```

**Expected Output:**
```
================================================================================
ğŸš€ STARTING ULTRA-OPTIMIZED gRPC SERVER
================================================================================
   âš¡ gRPC with HTTP/2
   âš¡ Protocol Buffers serialization
   âš¡ Pre-loaded videos in RAM
   âš¡ Memory-mapped audio features
   âš¡ Zero I/O overhead
================================================================================

ğŸ“¦ Loading optimized sanders...
ğŸ¯ Initializing Optimized Package: sanders
ğŸ“ Package directory: models\sanders
ğŸ“‹ Package: sanders v2.0
ğŸ“Š Frame count: 523
ğŸ“ Loading metadata...
  âœ… Crop rectangles: 523 frames cached
ğŸµ Memory-mapping audio features...
âœ… Audio features memory-mapped: (523, 512) (1.02 MB)
ğŸ¬ Pre-loading videos into RAM...
âœ… full_body_video: 523 frames loaded (1342.56 MB) in 5.23s
âœ… crops_328_video: 523 frames loaded (168.92 MB) in 0.87s
âœ… masks_video: 523 frames loaded (168.92 MB) in 0.82s
ğŸ“Š Total video memory: 1680.40 MB
ğŸ§  Loading neural network model...
âœ… Model loaded and warmed up on cuda
âœ… sanders loaded successfully!
   Frame count: 523
   Initialization time: 12.45s
   Device: cuda
ğŸš€ gRPC server listening on [::]:50051
ğŸ¯ Ready for ultra-fast inference!
```

**âœ… Success Criteria:**
- Server loads sans model (not default_model)
- All 3 videos loaded into RAM (~1.7GB)
- Model loaded on CUDA
- Server listening on port 50051

### Step 2: Start Go Proxy

Open a **second terminal**:

```powershell
cd D:\Projects\webcodecstest\grpc-websocket-proxy
.\run.bat
```

**Expected Output:**
```
================================================================================
ğŸŒ‰ GRPC-TO-WEBSOCKET PROXY SERVER (Multi-Backend Load Balancer)
================================================================================

ğŸ“ Backend configuration:
   [1] localhost:50051

ğŸ”Œ Connecting to 1 gRPC servers...
   [1/1] Connecting to localhost:50051...
   âœ… localhost:50051 - Status: running, Models: 1
âœ… Connected to 1/1 gRPC servers
ğŸš€ WebSocket proxy started on ws://localhost:8086/ws
ğŸ“ Static files served from ./static/
ğŸ¥ Health check: http://localhost:8086/health
âš–ï¸  Load balancing: Round-robin across 1 backends

Press Ctrl+C to stop
```

**âœ… Success Criteria:**
- Connected to gRPC server on 50051
- Health check shows "running" and "Models: 1"
- WebSocket listening on 8086/ws

### Step 3: Open Browser Client

Open in Chrome/Edge:
```
file:///D:/Projects/webcodecstest/webtest/realtime-lipsync-binary.html
```

### Step 4: Connect to Server

1. **Check WebSocket URL**: Should show `ws://localhost:8086/ws`
2. **Click "Connect to Server"**

**Expected in Browser Console:**
```
ğŸ”— Connecting to ws://localhost:8086/ws
âœ… WebSocket connected to ws://localhost:8086/ws
ğŸ“‹ Requesting model list...
ğŸ“‹ Available models: sanders
```

**Expected in Go Proxy Terminal:**
```
ğŸŒ Client connected: 127.0.0.1:xxxxx
âœ… ListModels: 1 models
```

**âœ… Success Criteria:**
- Status shows "Connected" (green)
- Model dropdown populates with "sanders"
- Console shows successful connection

### Step 5: Load Model Video

1. **Select Model**: Should auto-select "sanders"
2. **Click "ğŸ¬ Load Video"**

**Expected in Browser Console:**
```
ğŸ“ Loading model: sanders
ğŸ“Š Requesting metadata for sanders...
âœ… Metadata loaded: 523 frames, Videos: full_body, face_regions, masked_regions
ğŸ“¥ Loaded 10/523 frames...
ğŸ“¥ Loaded 20/523 frames...
...
ğŸ“¥ Loaded 523/523 frames...
âœ… All 523 frames loaded!
```

**Expected in Go Proxy Terminal:**
```
âœ… GetModelMetadata: sanders (523 frames)
âœ… GetVideoFrame: sanders frame 0 full_body (89234 bytes)
âœ… GetVideoFrame: sanders frame 1 full_body (91562 bytes)
...
```

**Expected in gRPC Server Terminal:**
```
(Nothing - video frames served from RAM, no logging)
```

**âœ… Success Criteria:**
- Progress bar reaches 100%
- Status shows "523 frames loaded"
- First video frame appears in canvas
- Total transfer: ~50-100 MB (523 frames Ã— ~100KB each)
- Load time: ~10-30 seconds (depends on network)

### Step 6: Test Real-Time Lip-Sync

1. **Click "ğŸ¤ Start Audio"**
2. **Allow microphone access**
3. **Speak into microphone**

**Expected in Browser Console:**
```
ğŸ¤ Starting audio capture...
âœ… Audio capture started
ğŸµ Audio chunk: 2048 samples
âš¡ Sending inference request: frame 0
ğŸ“¨ Binary response received: 85321 bytes
âš¡ Binary frame parsed: frame_id=0, processing_time=12ms, image_size=85321
```

**Expected in Go Proxy Terminal:**
```
âœ… sanders frame 0 [localhost:50051]: gRPC=12ms total=15ms size=85321 bytes
âœ… sanders frame 1 [localhost:50051]: gRPC=11ms total=14ms size=86234 bytes
```

**Expected in gRPC Server Terminal:**
```
(Inference requests are silent by design for performance)
```

**âœ… Success Criteria:**
- Lip-sync frames appear in real-time
- Processing time <20ms per frame
- No lag or stuttering
- Metrics show FPS ~30-50

## ğŸ” Troubleshooting

### Problem: "No backends available"

**Symptoms:**
- Go proxy shows error connecting to gRPC server
- Browser shows "no backends available"

**Solution:**
1. Check gRPC server is running: `netstat -an | findstr 50051`
2. Restart gRPC server
3. Restart Go proxy

### Problem: "Model video loading fails"

**Symptoms:**
- Progress bar stops
- Console shows timeout errors
- "Failed to load model video"

**Solution:**
1. Check gRPC server loaded model successfully
2. Check Go proxy connected to gRPC server
3. Try smaller batch size (edit `BATCH_SIZE = 10` to `5` in HTML)
4. Check browser console for specific error messages

### Problem: "Frame metadata error"

**Symptoms:**
- gRPC server fails to load model
- Error: "'processed_frames' KeyError"

**Solution:**
- This is fixed in latest code
- Make sure you pulled latest changes
- Check `optimized_inference_engine.py` line 197-200

### Problem: "Video frames not appearing"

**Symptoms:**
- Frames load but don't display
- Canvas is blank

**Solution:**
1. Check browser console for errors
2. Verify JPEG data is valid (check byte size >0)
3. Try reloading the page
4. Check `blobToDataURL()` method works

### Problem: "Lip-sync not working"

**Symptoms:**
- Video loaded but inference doesn't work
- No frames generated

**Solution:**
1. Check microphone permissions
2. Verify audio capture is working (check console for audio chunks)
3. Check gRPC server is responding to inference requests
4. Try restarting all components

## ğŸ“Š Performance Expectations

| Operation | Time | Notes |
|-----------|------|-------|
| gRPC Server Start | 10-15s | Loading videos into RAM |
| Go Proxy Start | 1-2s | Connecting to backends |
| Model List | <100ms | From memory |
| Model Metadata | <100ms | From memory |
| Single Video Frame | 10-50ms | JPEG encoding + transfer |
| Full Video Load (523 frames) | 10-30s | Batch loading with progress |
| Inference (per frame) | 10-20ms | GPU inference |
| End-to-End Latency | 50-100ms | Audio â†’ Result |

## ğŸ¯ Success Checklist

- [ ] gRPC server starts and loads sanders model
- [ ] Go proxy connects to gRPC server
- [ ] Browser connects to WebSocket
- [ ] Model list populates ("sanders")
- [ ] Model metadata loads (523 frames)
- [ ] All 523 video frames load successfully
- [ ] First frame displays in canvas
- [ ] Microphone audio capture works
- [ ] Real-time lip-sync inference works
- [ ] Processing time <20ms per frame
- [ ] No lag or stuttering

## ğŸš€ Next Steps

### If Everything Works:

1. **Test Multi-Model**:
   - Add more models to `minimal_server/models/`
   - Restart gRPC server
   - Switch between models in browser

2. **Test Multi-Backend**:
   - Start multiple gRPC servers on different ports
   - Update Go proxy: `--start-port 50051 --num-servers 4`
   - Verify load balancing works

3. **Performance Optimization**:
   - Implement frame caching in browser (IndexedDB)
   - Add progressive loading (load visible frames first)
   - Add video frame compression options
   - Consider ONNX optimization (15-25% faster)

### If Issues Persist:

1. Check all three terminals for error messages
2. Verify network connectivity (localhost)
3. Check firewall settings
4. Try restarting in sequence: gRPC â†’ Go Proxy â†’ Browser
5. Check browser console (F12) for detailed errors
6. Check `git log` to verify you have latest code

## ğŸ“ Architecture Benefits

**Before (Old Design):**
- âŒ HTTP static file server required
- âŒ Two protocols (HTTP + WebSocket)
- âŒ No load balancing for video
- âŒ Security issues (file system exposure)
- âŒ No server control over quality

**After (New Design):**
- âœ… Single WebSocket connection
- âœ… No HTTP server needed
- âœ… Load balancing for everything
- âœ… Secure (no file exposure)
- âœ… Server controls quality/caching
- âœ… Unified gRPC API
- âœ… Easy to scale (add more servers)

## ğŸ’¡ Tips

- **Batch Loading**: Adjust `BATCH_SIZE` in browser for optimal loading speed
- **Frame Caching**: Consider caching loaded frames in IndexedDB for faster reloads
- **Progressive Loading**: Load visible frames first, background frames later
- **Quality Control**: Add JPEG quality parameter to reduce transfer size
- **Monitoring**: Watch Go proxy logs to see request patterns
- **Debugging**: Use browser console (F12) to see detailed API calls

**Happy Testing!** ğŸ‰
