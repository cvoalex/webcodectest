# Minimal Binary Lip Sync Server

## ğŸš€ Ultra-Fast Real-Time Lip Sync System

This is a clean, minimal implementation of the high-performance binary lip sync server with optimized audio processing.

## ğŸ“ Files

### Core Server
- **`server.py`** - Main binary WebSocket server (port 8084)
- **`multi_model_engine.py`** - AI inference engine with binary optimization
- **`config.py`** - Configuration settings
- **`dynamic_model_manager.py`** - Model loading and management
- **`unet_328.py`** - Core AI model definition

### Dependencies
- **`data_utils/`** - Audio processing utilities (mel spectrograms)
- **`models/`** - Pre-trained AI model files

### Client
- **`client.html`** - Binary protocol client with real-time audio capture

## ğŸ”¥ Performance Features

- **Binary Protocol**: 150x faster than JSON
- **Direct Audio Processing**: 30-40% faster (no base64 conversion)
- **GPU Acceleration**: CUDA optimized inference
- **Real-time**: ~20-35ms inference times

## ğŸš€ Quick Start

1. **Start Server:**
   ```bash
   python server.py
   ```

2. **Open Client:**
   - Open `client.html` in browser
   - Allow microphone access
   - Click "Connect"
   - Start speaking to see lip sync!

## ğŸ“Š Server Logs

Watch for optimization indicators:
- âœ… `ğŸš€ OPTIMIZED: Processing raw bytes directly - NO BASE64!`
- âœ… `ğŸš€ OPTIMIZED: Raw binary audio processing succeeded`
- âš¡ `Binary inference times: ~20-35ms`

## ğŸŒ Connection

- **Server**: `ws://localhost:8084`
- **Protocol**: Binary WebSocket with JSON fallback
- **Audio**: 24kHz, 16-bit PCM, 640ms windows

## ğŸ¯ Audio Processing

- **Input**: 30,720 bytes (640ms of 24kHz audio)
- **Processing**: 16-chunk concatenation â†’ mel spectrogram
- **Output**: [1, 32, 16] tensor for AI inference
- **Response**: Real-time mouth movement prediction

This minimal server contains only essential files for maximum performance and maintainability.
