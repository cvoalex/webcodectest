# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: optimized_lipsyncsrv.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'optimized_lipsyncsrv.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1aoptimized_lipsyncsrv.proto\x12\x14optimized_lipsyncsrv\"A\n\x19OptimizedInferenceRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x10\n\x08\x66rame_id\x18\x02 \x01(\x05\"\xb6\x02\n\x1aOptimizedInferenceResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x17\n\x0fprediction_data\x18\x02 \x01(\x0c\x12\x0e\n\x06\x62ounds\x18\x03 \x03(\x02\x12\x1a\n\x12processing_time_ms\x18\x04 \x01(\x05\x12\x12\n\nmodel_name\x18\x05 \x01(\t\x12\x10\n\x08\x66rame_id\x18\x06 \x01(\x05\x12\x18\n\x10prediction_shape\x18\x07 \x01(\t\x12\x12\n\x05\x65rror\x18\x08 \x01(\tH\x00\x88\x01\x01\x12\x17\n\x0fprepare_time_ms\x18\t \x01(\x01\x12\x19\n\x11inference_time_ms\x18\n \x01(\x01\x12\x19\n\x11\x63omposite_time_ms\x18\x0b \x01(\x01\x12\x15\n\roptimizations\x18\x0c \x03(\tB\x08\n\x06_error\">\n\x15\x42\x61tchInferenceRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x11\n\tframe_ids\x18\x02 \x03(\x05\"w\n\x1e\x42\x61tchInferenceWithAudioRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x16\n\x0estart_frame_id\x18\x02 \x01(\x05\x12\x13\n\x0b\x66rame_count\x18\x03 \x01(\x05\x12\x14\n\x0c\x61udio_chunks\x18\x04 \x03(\x0c\"\x9a\x01\n\x16\x42\x61tchInferenceResponse\x12\x43\n\tresponses\x18\x01 \x03(\x0b\x32\x30.optimized_lipsyncsrv.OptimizedInferenceResponse\x12 \n\x18total_processing_time_ms\x18\x02 \x01(\x05\x12\x19\n\x11\x61vg_frame_time_ms\x18\x03 \x01(\x01\"?\n\x12LoadPackageRequest\x12\x14\n\x0cpackage_name\x18\x01 \x01(\t\x12\x13\n\x0bpackage_dir\x18\x02 \x01(\t\"\x82\x02\n\x13LoadPackageResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x14\n\x0cpackage_name\x18\x02 \x01(\t\x12\x0f\n\x07message\x18\x03 \x01(\t\x12\x1e\n\x16initialization_time_ms\x18\x04 \x01(\x05\x12\x13\n\x0b\x66rame_count\x18\x05 \x01(\x05\x12\x0e\n\x06\x64\x65vice\x18\x06 \x01(\t\x12\x15\n\rvideos_loaded\x18\x07 \x03(\t\x12\x1c\n\x14\x61udio_features_shape\x18\x08 \x03(\x05\x12\x1b\n\x13memory_mapped_audio\x18\t \x01(\x08\x12\x12\n\x05\x65rror\x18\n \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"\"\n\x0cStatsRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\"\xdb\x01\n\rStatsResponse\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x16\n\x0etotal_requests\x18\x02 \x01(\x05\x12\x1d\n\x15\x61vg_inference_time_ms\x18\x03 \x01(\x01\x12\x1d\n\x15min_inference_time_ms\x18\x04 \x01(\x01\x12\x1d\n\x15max_inference_time_ms\x18\x05 \x01(\x01\x12\x13\n\x0b\x66rame_count\x18\x06 \x01(\x05\x12\x0e\n\x06\x64\x65vice\x18\x07 \x01(\t\x12\x1c\n\x14optimizations_active\x18\x08 \x03(\t\"\x13\n\x11ListModelsRequest\":\n\x12ListModelsResponse\x12\x15\n\rloaded_models\x18\x01 \x03(\t\x12\r\n\x05\x63ount\x18\x02 \x01(\x05\"\x0f\n\rHealthRequest\"`\n\x0eHealthResponse\x12\x0f\n\x07healthy\x18\x01 \x01(\x08\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x15\n\rloaded_models\x18\x03 \x01(\x05\x12\x16\n\x0euptime_seconds\x18\x04 \x01(\x03\"P\n\x14GetVideoFrameRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x10\n\x08\x66rame_id\x18\x02 \x01(\x05\x12\x12\n\nvideo_type\x18\x03 \x01(\t\"\x80\x01\n\x15GetVideoFrameResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x12\n\nframe_data\x18\x02 \x01(\x0c\x12\x10\n\x08\x66rame_id\x18\x03 \x01(\x05\x12\x12\n\nvideo_type\x18\x04 \x01(\t\x12\x12\n\x05\x65rror\x18\x05 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error\"-\n\x17GetModelMetadataRequest\x12\x12\n\nmodel_name\x18\x01 \x01(\t\"\xb0\x01\n\x18GetModelMetadataResponse\x12\x0f\n\x07success\x18\x01 \x01(\x08\x12\x12\n\nmodel_name\x18\x02 \x01(\t\x12\x13\n\x0b\x66rame_count\x18\x03 \x01(\x05\x12\x18\n\x10\x61vailable_videos\x18\x04 \x03(\t\x12\x12\n\naudio_path\x18\x05 \x01(\t\x12\x0e\n\x06\x62ounds\x18\x06 \x03(\x02\x12\x12\n\x05\x65rror\x18\x07 \x01(\tH\x00\x88\x01\x01\x42\x08\n\x06_error2\xcf\x08\n\x17OptimizedLipSyncService\x12v\n\x11GenerateInference\x12/.optimized_lipsyncsrv.OptimizedInferenceRequest\x1a\x30.optimized_lipsyncsrv.OptimizedInferenceResponse\x12s\n\x16GenerateBatchInference\x12+.optimized_lipsyncsrv.BatchInferenceRequest\x1a,.optimized_lipsyncsrv.BatchInferenceResponse\x12|\n\x16GenerateBatchWithAudio\x12\x34.optimized_lipsyncsrv.BatchInferenceWithAudioRequest\x1a,.optimized_lipsyncsrv.BatchInferenceResponse\x12x\n\x0fStreamInference\x12/.optimized_lipsyncsrv.OptimizedInferenceRequest\x1a\x30.optimized_lipsyncsrv.OptimizedInferenceResponse(\x01\x30\x01\x12\x62\n\x0bLoadPackage\x12(.optimized_lipsyncsrv.LoadPackageRequest\x1a).optimized_lipsyncsrv.LoadPackageResponse\x12S\n\x08GetStats\x12\".optimized_lipsyncsrv.StatsRequest\x1a#.optimized_lipsyncsrv.StatsResponse\x12_\n\nListModels\x12\'.optimized_lipsyncsrv.ListModelsRequest\x1a(.optimized_lipsyncsrv.ListModelsResponse\x12X\n\x0bHealthCheck\x12#.optimized_lipsyncsrv.HealthRequest\x1a$.optimized_lipsyncsrv.HealthResponse\x12h\n\rGetVideoFrame\x12*.optimized_lipsyncsrv.GetVideoFrameRequest\x1a+.optimized_lipsyncsrv.GetVideoFrameResponse\x12q\n\x10GetModelMetadata\x12-.optimized_lipsyncsrv.GetModelMetadataRequest\x1a..optimized_lipsyncsrv.GetModelMetadataResponseB\x06Z\x04./pbb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'optimized_lipsyncsrv_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'Z\004./pb'
  _globals['_OPTIMIZEDINFERENCEREQUEST']._serialized_start=52
  _globals['_OPTIMIZEDINFERENCEREQUEST']._serialized_end=117
  _globals['_OPTIMIZEDINFERENCERESPONSE']._serialized_start=120
  _globals['_OPTIMIZEDINFERENCERESPONSE']._serialized_end=430
  _globals['_BATCHINFERENCEREQUEST']._serialized_start=432
  _globals['_BATCHINFERENCEREQUEST']._serialized_end=494
  _globals['_BATCHINFERENCEWITHAUDIOREQUEST']._serialized_start=496
  _globals['_BATCHINFERENCEWITHAUDIOREQUEST']._serialized_end=615
  _globals['_BATCHINFERENCERESPONSE']._serialized_start=618
  _globals['_BATCHINFERENCERESPONSE']._serialized_end=772
  _globals['_LOADPACKAGEREQUEST']._serialized_start=774
  _globals['_LOADPACKAGEREQUEST']._serialized_end=837
  _globals['_LOADPACKAGERESPONSE']._serialized_start=840
  _globals['_LOADPACKAGERESPONSE']._serialized_end=1098
  _globals['_STATSREQUEST']._serialized_start=1100
  _globals['_STATSREQUEST']._serialized_end=1134
  _globals['_STATSRESPONSE']._serialized_start=1137
  _globals['_STATSRESPONSE']._serialized_end=1356
  _globals['_LISTMODELSREQUEST']._serialized_start=1358
  _globals['_LISTMODELSREQUEST']._serialized_end=1377
  _globals['_LISTMODELSRESPONSE']._serialized_start=1379
  _globals['_LISTMODELSRESPONSE']._serialized_end=1437
  _globals['_HEALTHREQUEST']._serialized_start=1439
  _globals['_HEALTHREQUEST']._serialized_end=1454
  _globals['_HEALTHRESPONSE']._serialized_start=1456
  _globals['_HEALTHRESPONSE']._serialized_end=1552
  _globals['_GETVIDEOFRAMEREQUEST']._serialized_start=1554
  _globals['_GETVIDEOFRAMEREQUEST']._serialized_end=1634
  _globals['_GETVIDEOFRAMERESPONSE']._serialized_start=1637
  _globals['_GETVIDEOFRAMERESPONSE']._serialized_end=1765
  _globals['_GETMODELMETADATAREQUEST']._serialized_start=1767
  _globals['_GETMODELMETADATAREQUEST']._serialized_end=1812
  _globals['_GETMODELMETADATARESPONSE']._serialized_start=1815
  _globals['_GETMODELMETADATARESPONSE']._serialized_end=1991
  _globals['_OPTIMIZEDLIPSYNCSERVICE']._serialized_start=1994
  _globals['_OPTIMIZEDLIPSYNCSERVICE']._serialized_end=3097
# @@protoc_insertion_point(module_scope)
